{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# SỐ HÓA TỦ SÁCH - DIGITIZATION OF BOOKCASE\n","Nhóm tác giả :\n","\n","* Nguyễn Gia Bảo Ngọc - 21520366\n","\n","* Nguyễn Quốc Trường An - 21521810\n","\n","* Nguyễn Đức Tú - 21521612\n","\n","Việc xây dựng notebook có sự tham khảo từ bài viết: https://www.learndatasci.com/glossary/binary-classification/?fbclid=IwAR02W006ehuA1xYUYLZ38g138tGSZ71VYXZha88CiklLQVJ2l13WqWvkVqc\n","\n","và sự hỗ trợ từ ChatGPT.\n","\n","\n","# Outline\n","- [ 1 - Truyền dữ Liệu](#1)\n","- [ 2 - Training model Classification](#2)\n","- [ 3 - Thực thi Pipeline Machine Learning](#3)"],"metadata":{"id":"qeaHSWpZTZ7Z"}},{"cell_type":"markdown","source":["<a name=\"1\"></a>\n","## 1 - Truyền dữ liệu\n","- Dữ liệu sẽ được truyền từ đường dẫn '/content/final_data_set.txt' với 'final_data_set.txt' là dữ liệu được dùng cho việc huấn luyện model.\n","- Sau khi dữ liệu được truyền, tiếp tục thực hiện một số bước kiểm tra tính hợp lệ, thông tin cơ bản của tập dữ liệu."],"metadata":{"id":"uh49CxlVZ_4Z"}},{"cell_type":"markdown","source":["Truyền dữ liệu và hiển thị cơ bản DataFrame"],"metadata":{"id":"qYgq_NGgbPJe"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Đường dẫn tới tệp\n","file_path = '/content/final_data_set.txt'\n","\n","# Đọc tệp dữ liệu\n","dataset = pd.read_csv(file_path, sep='[\\t\\s]+', header=None, engine='python')\n","dataset.columns = ['left','top','width', 'heigth', 'size', 'center', 'title']\n","\n","# Hiển thị cơ bản về DataFrame\n","dataset"],"metadata":{"id":"AUa0-brrjTxV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Hiển thị thông tin chi tiết về DataFrame, kiểm tra tính hợp lê (kiểu dữ liệu, có phần tử nào rỗng không,...)"],"metadata":{"id":"IBu6lQVXbBqU"}},{"cell_type":"code","source":["df= dataset\n","print(\"Kiểu dữ liệu của từng cột:\")\n","print(df.dtypes)\n","\n","# Sử dụng info()\n","print(\"\\nThông tin chi tiết về DataFrame:\")\n","print(df.info())"],"metadata":{"id":"8qA39I_0FBQI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Thông tin các 'Feature':"],"metadata":{"id":"2KV4qFu6bfPU"}},{"cell_type":"code","source":["dataset.iloc[:, :6]"],"metadata":{"id":"P1BueszoR1CF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Thông tin về 'Target':"],"metadata":{"id":"_7bspdqIbnSq"}},{"cell_type":"code","source":["dataset.iloc[:, 6:]"],"metadata":{"id":"gveu2SfBR-Ii"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Các cột 'Feature' và cột 'Target' trong dữ liệu ban đầu sẽ được tách ra và truyền lần lượt vào X và Y, thể hiện cho Input và Output"],"metadata":{"id":"1zt2RQL8cIaQ"}},{"cell_type":"code","source":["X = dataset.iloc[:, :6]\n","y = dataset.iloc[:, 6:]"],"metadata":{"id":"1Ut1vKMASIR-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dữ liệu được chia vào các tập 'Train' và 'Test' với tỉ lệ lần lượt là 75% và 25%"],"metadata":{"id":"Zv_zglirc9i3"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.25, random_state=0)\n"],"metadata":{"id":"gCgGzQawSe26"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.iloc[:1,:]"],"metadata":{"id":"wIczgTr3rzme"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train.iloc[:1,:]"],"metadata":{"id":"LQauk7sFsDlM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train = y_train.values.ravel()\n","y_test = y_test.values.ravel()"],"metadata":{"id":"O3ahyvoiSMdJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a name=\"1\"></a>\n","## 2 - Training model Classifiction\n","- Việc thực hiện phần này nhận được sự tham khảo từ bài viết: https://www.learndatasci.com/glossary/binary-classification/?fbclid=IwAR02W006ehuA1xYUYLZ38g138tGSZ71VYXZha88CiklLQVJ2l13WqWvkVqc\n","\n","- Tập dữ liệu sẽ được để huấn luyện cho 6 model phổ biến nhất cho Binary Classifiction là: Logistic Regression, Support Vector Machines, Decision Trees, Random Forest, Naive Bayes, K-Nearest Neighbor.\n","- Sau khi thực hiện huấn luyện sẽ chọn ra model có thông số F1-score tốt nhất để tích hợp vào Pipeline Machine Learning"],"metadata":{"id":"tmQ9tYdec7t5"}},{"cell_type":"markdown","source":["Feature Scaling:"],"metadata":{"id":"1tROgaWSeihs"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import confusion_matrix\n","ss_train = StandardScaler()\n","X_train = ss_train.fit_transform(X_train)\n","\n","ss_test = StandardScaler()\n","X_test = ss_test.fit_transform(X_test)"],"metadata":{"id":"Fg9Jsy1pSjD2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Thiết lập các model cần dùng:"],"metadata":{"id":"tgVmsEZbeqak"}},{"cell_type":"code","source":["models = {}\n","\n","# Logistic Regression\n","from sklearn.linear_model import LogisticRegression\n","models['Logistic Regression'] = LogisticRegression()\n","\n","# Support Vector Machines\n","from sklearn.svm import LinearSVC\n","models['Support Vector Machines'] = LinearSVC()\n","\n","# Decision Trees\n","from sklearn.tree import DecisionTreeClassifier\n","models['Decision Trees'] = DecisionTreeClassifier()\n","\n","# Random Forest\n","from sklearn.ensemble import RandomForestClassifier\n","models['Random Forest'] = RandomForestClassifier()\n","\n","# Naive Bayes\n","from sklearn.naive_bayes import GaussianNB\n","models['Naive Bayes'] = GaussianNB()\n","\n","# K-Nearest Neighbors\n","from sklearn.neighbors import KNeighborsClassifier\n","models['K-Nearest Neighbor'] = KNeighborsClassifier()"],"metadata":{"id":"y2GqiKGTSu68"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["  - Tiến hành huấn luyện các model dựa trên tập dữ liệu Train, ghi nhận lại các số liệu: accuracy_score, precision_score, recall_score, F1_score.\n","  - Cho biết model nào có F1_score tốt nhất\n"],"metadata":{"id":"KuABUTxoe0d7"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","accuracy, precision, recall, f1_s = {}, {}, {}, {}\n","\n","for key in models.keys():\n","\n","    # Fit the classifier\n","    models[key].fit(X_train, y_train)\n","\n","    # Make predictions\n","    predictions = models[key].predict(X_test)\n","\n","    # Calculate metrics\n","    accuracy[key] = accuracy_score(predictions, y_test)\n","    precision[key] = precision_score(predictions, y_test)\n","    recall[key] = recall_score(predictions, y_test)\n","    f1_s[key] = f1_score(predictions, y_test)\n","best_model_key = max(f1_s, key=f1_s.get)\n","print('Best model is: '+best_model_key)"],"metadata":{"id":"7jTgtI4sTIMT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Thông tin chi tiết về accuracy, precision, recall, f1_score của từng model:"],"metadata":{"id":"94s308zAfUfg"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","df_model = pd.DataFrame(index=models.keys(), columns=['Accuracy', 'Precision', 'Recall', 'F1-score'])\n","df_model['Accuracy'] = accuracy.values()\n","df_model['Precision'] = precision.values()\n","df_model['Recall'] = recall.values()\n","df_model['F1-score'] = f1_s.values()\n","\n","df_model"],"metadata":{"id":"xVtFB-kMTbwG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ax = df_model.plot.barh()\n","ax.legend(\n","    ncol=len(models.keys()),\n","    bbox_to_anchor=(0, 1),\n","    loc='lower left',\n","    prop={'size': 14}\n",")\n","plt.tight_layout()"],"metadata":{"id":"Ux1_SXIdTge0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Confusion Matrix của model được chọn là tốt nhất:"],"metadata":{"id":"RN-MUBOqg17k"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","models[best_model_key].fit(X_train, y_train)\n","predictions = models[best_model_key].predict(X_test)\n","cm = confusion_matrix(y_test, predictions)\n","\n","TN, FP, FN, TP = confusion_matrix(y_test, predictions).ravel()\n","\n","print('True Positive(TP)  = ', TP)\n","print('False Positive(FP) = ', FP)\n","print('True Negative(TN)  = ', TN)\n","print('False Negative(FN) = ', FN)\n","\n","labels = np.array([['True Negative\\n{}'.format(TN), 'False Positive\\n{}'.format(FP)],\n","                   ['False Negative\\n{}'.format(FN), 'True Positive\\n{}'.format(TP)]])\n","\n","# Vẽ Confusion Matrix với số lượng và nhãn\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(cm, annot=labels, fmt=\"\", cmap=\"Blues\", cbar=False)\n","plt.title(\"Confusion Matrix of \"+ best_model_key)\n","plt.show()"],"metadata":{"id":"ECxl4YcKaqzg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<a name=\"1\"></a>\n","## 3 - Thực thi Pipeline Machine Learning\n","- Pipeline gồm 3 bước cơ bản nhất là: Text Detection, Classification, Text Extraction.\n","- Text Detection: sử dụng công cụ tesseract, để khoanh vùng vùng chứa văn bản.\n","- Classification: là model Classification tốt nhất được lựa chọn ở trên, dùng để dự đoán vùng chứa văn bản nào có bao gồm tựa của sách hay không.\n","- Text Extraction: sử dụng công cụ easyocr, để tách văn bản ra khỏi ảnh được dự đoán là có chứa tựa sách.\n","- Thứ tự thực hiện sẽ là: Text Detection, Classification, Text Extraction."],"metadata":{"id":"QoK-4o1ThxrN"}},{"cell_type":"markdown","source":["Tải các công cụ cần dùng:"],"metadata":{"id":"c2RT66s8jN1f"}},{"cell_type":"code","source":["!sudo apt install tesseract-ocr"],"metadata":{"id":"VHGpaanUBSk_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pytesseract"],"metadata":{"id":"Jo6TaAJzBQ4E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!sudo apt install tesseract-ocr-vie"],"metadata":{"id":"PSRNIQ2ahmrZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install easyocr"],"metadata":{"id":"YgXz4VJam4Xb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab.patches import cv2_imshow\n","import pytesseract\n","import cv2\n","import numpy as np\n","import easyocr"],"metadata":{"id":"6qguBvu4BNU-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Hàm xử lí ảnh cơ bản phục vụ cho giai đoạn Text Detection:"],"metadata":{"id":"2aEp3JVcjgjQ"}},{"cell_type":"code","source":["def process_img (image):\n","  image= cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","  image= cv2.bitwise_not(image)\n","  kernel = np.ones((2, 2), np.uint8)\n","  image = cv2.dilate(image, kernel, iterations=1)\n","  image = cv2.erode(image, kernel, iterations=1)\n","  return image"],"metadata":{"id":"sFlRFNjkBIYR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Hàm xử lí ảnh cơ bản phục vụ cho giai đoạn Text Extraction:"],"metadata":{"id":"UktoRFUEjvZl"}},{"cell_type":"code","source":["def enhance_image_for_ocr(image):\n","    # Chuyển đổi sang grayscale\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    # Áp dụng denoising\n","    denoised = cv2.medianBlur(gray, 1)\n","    # Tăng độ tương phản\n","    alpha = 1.5  # Hệ số tương phản\n","    beta = 0     # Độ sáng\n","    contrast = cv2.convertScaleAbs(denoised, alpha=alpha, beta=beta)\n","    return contrast"],"metadata":{"id":"VT1fPN0qjcSn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["GIAI ĐOẠN TEXT DETECTION:\n","\n","-   'd = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)' là mấu chốt cho việc phát hiện vùng chứa văn bản, lưu các thông tin về vùng đó.\n","- 'if d['level'][i] == 2:' đây là câu lệnh quan trọng kế tiếp, xác định các vùng ở level 2 bao gồm các đoạn văn (nhiều kí tự, từ, hàng) phù hợp với tính chất của một tựa sách. Các level thấp hơn sẽ nhận diện là các kí tự, các từ,... không phù hợp với tính chất của một tựa sách.\n","- Tính toán xử lí để trả về các thông tin: left, top, width, height, size, center, để làm thông tin ngõ vào cho giai đoạn tiếp theo"],"metadata":{"id":"vOKfESD8j3b6"}},{"cell_type":"code","source":["def detect_text (image_path):\n","  image = cv2.imread(image_path)\n","  image = process_img(image)\n","  height, width = image.shape\n","  image_center = (width / 2, height / 2) #tâm ảnh\n","  min_distance = float('inf')\n","  center_box = None\n","  d = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)\n","  box = []\n","  boxes_with_distances = []\n","  for i in range(len(d['level'])):\n","        if d['level'][i] == 2:\n","          (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n","          box.append((x, y, w, h, w*h))\n","          box_center = (x + w / 2, y + h / 2)\n","          distance = np.sqrt((box_center[0] - image_center[0])**2 + (box_center[1] - image_center[1])**2)\n","          boxes_with_distances.append(((x, y, w, h), distance))\n","\n","  boxes_with_distances.sort(key=lambda x: x[1])\n","  final_box = ()\n","    # Lấy 3 hộp gần trung tâm nhất\n","  closest_boxes = boxes_with_distances[:3]\n","    # Lấy các tọa độ box từ closest_boxes để so sánh\n","  closest_coords = [box[0] for box in closest_boxes]\n","\n","    # Thêm 1 nếu box nằm trong closest_boxes, ngược lại thêm 0 tạo feture center\n","  final_boxes = [box + (1,) if box[:4] in closest_coords else box + (0,) for box in box]\n","\n","  return final_boxes\n"],"metadata":{"id":"s0oi1b7yBEoc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["GIAI ĐOẠN CLASSIFICATION VÀ GIAI ĐOẠN TEXT EXTRACTION:\n","- GIAI ĐOẠN CLASSIFICATION:\n","    * Dữ liệu được trả về từ giai đoạn Text extraction, cũng là dữ liệu đầu vào cho giai đoạn Classification.\n","    * Tương tự như việc dự đoán cho tập Test ở phần 2, model Classification tiếp tục thực hiện dự đoán cho tập dữ liệu được trả về từ giai đoạn Text Detection.\n","    * Biến `predictions` lưu trữ lại kết quả dự đoán các vùng văn bản được phát hiệu trên từng ảnh (`predictions` chỉ lưu giá trị dự đoán cho một ảnh tại một thời điểm). Biến `predictions` cũng là kết quả đầu ra cho giai đoạn Classification.\n","- GIAI ĐOẠN TEXT EXTRACTION:\n","    * Dữ liệu được trả về từ giai đoạn Classification và giai đoạn Text Detection sẽ là dữ liệu ngõ vào cho giải đoạn Text Extraction\n","    * Cụ thể dữ liệu được trả về từ giai đoạn Classification sẽ dự đoán vùng văn bản có chứa tựa sách, giá trị trả về của giai đoạn Text Detection sẽ cho biết thông tin về các vùng có chứa văn bản, kết hợp giá trị trả về của cả hai giai đoạn ta sẽ cho được thông tin về vùng được dự đoán là có chứa tựa sách.\n","    * Sau khi đã có thông tin về vùng được dự đoán là có chứa tựa sách, bước tiếp theo là tách vùng văn bản đó bằng đoạn lệnh:\n","    \n","      `reader = easyocr.Reader(['en','vi'])`\n","\n","     `text_extarcted= reader.readtext(enhance_image_for_ocr(handled_image))`\n","\n","    * Tựa sách sau cùng sẽ có thể được chưa trong biến `text_extarcted`"],"metadata":{"id":"N3o-zKoknd8L"}},{"cell_type":"code","source":["target_size = (480, 270) #dài rộng\n","\n","#----------------------GIAI ĐOẠN CLASSIFICATION------------------------------------------\n","for i in range(1, 75):\n","  print('-----------------'+' book '+str(i)+' -----------------------------------------')\n","  data= detect_text('/content/img ('+str(i)+').JPG')\n","  image = cv2.imread('/content/img ('+str(i)+').JPG')\n","  img_height, img_width = image.shape[:2]\n","  #cv2_imshow(image)\n","  df = pd.DataFrame(data, columns=['left', 'top', 'width', 'height', 'size', 'center'])\n","  df_temp = df\n","  df.info\n","  ss_train = StandardScaler()\n","  df = ss_train.fit_transform(df)\n","  models[best_model_key].fit(X_train, y_train)\n","  predictions = models[best_model_key].predict(df)\n","\n","#----------------------GIAI ĐOẠN TEXT EXTRACTION------------------------------------------\n","  title = ''\n","  for index, row in df_temp[predictions == 1].iterrows():\n","      # Các thông số để cắt ảnh\n","      left, top, width, height = row['left'], row['top'], row['width'], row['height']\n","      left = max(row['left'] - 10, 0)  # Giảm left nhưng không để nó âm\n","      top = max(row['top'] - 10, 0)\n","      width = min(row['width']+20, img_width-left)\n","      height = min(row['height']+20, img_height-top)\n","      # Cắt ảnh\n","      handled_image = image[top:top+height, left:left+width]\n","      handled_image = cv2.resize(handled_image, target_size)\n","      # Đọc văn bản từ ảnh\n","      reader = easyocr.Reader(['en','vi'])\n","      text_extarcted= reader.readtext(enhance_image_for_ocr(handled_image))\n","\n","      for text in text_extarcted:\n","        if text[2] >0.1:\n","          title += text[1]+' '\n","      # Hiển thị ảnh được dự đoán là tựa sách\n","      cv2_imshow(handled_image)\n","      print('title: '+title)\n"],"metadata":{"id":"tBUIUEvvHxPP"},"execution_count":null,"outputs":[]}]}